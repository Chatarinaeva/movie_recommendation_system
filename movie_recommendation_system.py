# -*- coding: utf-8 -*-
"""Recommendation_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JIpL4rEaLLhCdcMWuz3e0xiMbSakUIwF

# **Movie Recommendation System Using Content-Based and Collaborative Filtering**
- **Nama:** Chatarina Evangelista Sitorus
- **Email:** chatarinaevas304@gmail.com
- **ID Dicoding:** dicodingchatzz

## **Project Overview**

Industri hiburan digital telah mengalami perkembangan pesat dalam dekade terakhir, terutama melalui layanan *streaming* seperti Netflix, Disney+, dan Amazon Prime. Namun, semakin banyaknya pilihan film justru memunculkan tantangan baru bagi pengguna, yakni kesulitan dalam menemukan tontonan yang relevan dan sesuai preferensi. Untuk mengatasi permasalahan ini, sistem rekomendasi hadir sebagai solusi yang efektif dalam menyaring informasi serta meningkatkan pengalaman pengguna secara personal dan efisien.

Proyek ini bertujuan membangun sistem rekomendasi film berbasis *machine learning* menggunakan dua pendekatan utama: *Content-Based Filtering* (CBF) dan *Collaborative Filtering* (CF). CBF memanfaatkan informasi konten seperti genre untuk mengukur kemiripan antar film  [[3]](https://doi.org/10.21108/ijoict.v9i2.747), sedangkan CF menggunakan data historis interaksi pengguna untuk memprediksi preferensi baru berdasarkan kemiripan pola dengan pengguna lain [[1]](https://doi.org/10.1109/ICESC48915.2020.9155879).

Algor dan Srivastava [[1]](https://doi.org/10.1109/ICESC48915.2020.9155879) menunjukkan bahwa *deep learning*-based models dan metrik kemiripan seperti *cosine similarity* sangat efektif dalam sistem CBF, sementara pendekatan CF terbukti efektif dalam mengatasi permasalahan *cold-start item*. Nurhaida dan Marzuki [[3]](https://doi.org/10.21108/ijoict.v9i2.747) mendukung efektivitas *cosine similarity* untuk menganalisis kemiripan konten berbasis genre. Nand dan Tripathi [[4]](https://doi.org/10.12720/jait.12.3.189-196) menambahkan bahwa penggunaan metode hybrid seperti K-Means dan TF-IDF mampu meningkatkan akurasi sistem rekomendasi. Sementara itu, Rukmi *et al.* [[2]](https://doi.org/10.47738/jads.v4i3.115) menekankan bahwa pemilihan algoritma sistem rekomendasi memiliki dampak langsung terhadap kepuasan dan retensi pengguna dalam layanan hiburan digital.

## **Business Understanding**

Dengan mempertimbangkan latar belakang tersebut, maka proyek ini dirancang dengan tujuan dan strategi sebagai berikut.

### **Problem Statements**

- Bagaimana membangun sistem rekomendasi film yang mampu menyarankan film serupa berdasarkan genre dari film yang telah disukai pengguna sebelumnya (CBF)?

- Bagaimana merancang model rekomendasi yang dapat memanfaatkan pola rating pengguna lain untuk menyarankan film yang relevan secara personal (CF)?

- Bagaimana mengevaluasi performa kedua pendekatan sistem rekomendasi dan menentukan pendekatan yang paling efektif untuk konteks ini?

### **Goals**

- Mengembangkan model *Content-Based Filtering* menggunakan representasi TF-IDF pada data genre dan menghitung kemiripan antar film menggunakan cosine similarity.

- Mengembangkan model *Collaborative Filtering* berbasis neural network untuk mempelajari representasi pengguna dan film dalam bentuk *embedding*, lalu memprediksi kemungkinan rating pada film yang belum ditonton.

- Menghasilkan daftar Top-N Recommendation untuk pengguna dan membandingkan kinerja kedua pendekatan berdasarkan metrik evaluasi seperti RMSE.

### **Solution statements**

Untuk mencapai tujuan di atas, dua pendekatan sistem rekomendasi diterapkan:

- *Content-Based Filtering* (CBF):
Genre dari setiap film akan diolah menggunakan TF-IDF Vectorizer, kemudian dihitung tingkat kemiripannya antar film menggunakan cosine similarity. Sistem akan merekomendasikan film dengan skor kemiripan tertinggi terhadap film yang pernah ditonton pengguna.

- *Collaborative Filtering* (CF):
Model dibangun dengan pendekatan embedding neural network yang mempelajari hubungan laten antara user dan item. Model kemudian memprediksi skor ketertarikan pengguna terhadap film yang belum mereka tonton, lalu memilih rekomendasi berdasarkan skor tertinggi.

## **Import Packages/Library**

Tahapan ini dilakukan untuk memuat seluruh library yang dibutuhkan dalam proses analisis data, visualisasi, dan pembuatan model machine learning.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import os
import shutil
import kagglehub
from google.colab import drive
from pathlib import Path
from collections import Counter

# Pemrosesan teks & similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Preprocessing untuk collaborative filtering
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# Deep Learning untuk collaborative filtering
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Model, regularizers
from tensorflow.keras import layers

"""## **Data Loading**

Dataset yang digunakan dalam proyek ini berasal dari Kaggle, yaitu [Movie Recommender System](https://www.kaggle.com/datasets/gargmanas/movierecommenderdataset) dengan ID `gargmanas/movierecommenderdataset`.

Proses pemuatan data dilakukan menggunakan `KaggleHub`, kemudian disalin ke `Google Drive` agar file `.csv` bisa diakses secara stabil di lingkungan Google Colab. Tahapan utamanya mencakup:

- Mengunduh file dataset langsung dari Kaggle.
- Menyimpan file `.csv` ke dalam direktori di Google Drive.
- Membaca file menggunakan `pandas` untuk dimuat sebagai DataFrame.

Pendekatan ini dipilih untuk menjaga ketersediaan dataset secara berkelanjutan, terutama ketika runtime Colab sewaktu-waktu mengalami disconnect.

- Memuat dataset Movie Recommender System Dataset menggunakan KaggleHub
"""

drive.mount('/content/drive')

kaggle_path = kagglehub.dataset_download("gargmanas/movierecommenderdataset")
print("Dataset berhasil diunduh dari KaggleHub ke:", kaggle_path)

# Lihat isi folder hasil unduhan
print("Daftar file dalam folder:", kaggle_path)
print(os.listdir(kaggle_path))

# Path file asli
movies_src = os.path.join(kaggle_path, "movies.csv")
ratings_src = os.path.join(kaggle_path, "ratings.csv")
print("File movies ditemukan di:", movies_src)
print("File ratings ditemukan di:", ratings_src)

# Path tujuan di Google Drive
target_dir = "/content/drive/MyDrive/Coding Camp 2025/ML Terapan/Proyek Akhir/"
os.makedirs(target_dir, exist_ok=True)

movies_dst = os.path.join(target_dir, "movies.csv")
ratings_dst = os.path.join(target_dir, "ratings.csv")

# Salin ke Google Drive
shutil.copy(movies_src, movies_dst)
shutil.copy(ratings_src, ratings_dst)
print("Dataset berhasil disalin ke Google Drive:")
print("-", movies_dst)
print("-", ratings_dst)

# Load ulang dataset dari Google Drive
df_movies = pd.read_csv(movies_dst)
df_ratings = pd.read_csv(ratings_dst)

"""- Menampilkan 5 baris data teratas dari DataFrame Movies"""

df_movies.head()

"""- Menampilkan 5 baris data teratas dari DataFrame Ratings"""

df_ratings.head()

"""### Deskripsi Singkat Fitur

Dataset yang digunakan terdiri atas dua file utama: `movies.csv` dan `ratings.csv`, yang masing-masing merepresentasikan informasi tentang film dan penilaian dari pengguna. Kedua dataset akan digabungkan melalui kolom `movieId` untuk membentuk sistem rekomendasi berbasis konten maupun preferensi pengguna.

Berikut adalah penjelasan fitur-fitur pada masing-masing dataset:

#### Deskripsi Fitur `df_movies`

| **Fitur**   | **Deskripsi**                                                                 |
|-------------|-------------------------------------------------------------------------------|
| `movieId`   | ID unik untuk setiap film                                                     |
| `title`     | Judul film lengkap dengan tahun rilis                                         |
| `genres`    | Daftar genre film yang dipisahkan dengan tanda pipe (&#124;)                  |

#### Deskripsi Fitur `df_ratings`

| **Fitur**     | **Deskripsi**                                                                 |
|---------------|-------------------------------------------------------------------------------|
| `userId`      | ID unik untuk setiap pengguna                                                 |
| `movieId`     | ID film yang dinilai (relasi ke `df_movies`)                                 |
| `rating`      | Nilai penilaian dari pengguna terhadap film (skala 0.5 sampai 5.0)            |
| `timestamp`   | Waktu rating diberikan (format UNIX timestamp, belum dikonversi ke tanggal)  |

## **Exploratory Data Analysis (EDA) / Data Understanding**

Tahap ini bertujuan untuk memahami struktur dan karakteristik awal dari masing-masing dataset (`df_movies` dan `df_ratings`) yang akan digunakan untuk membangun sistem rekomendasi film. Melalui EDA, potensi masalah dalam data seperti duplikasi, nilai kosong, atau data tidak konsisten dapat diidentifikasi sejak awal. Selain itu, tahap ini membantu dalam mengenali pola atau distribusi data penting sebelum dilakukan proses preprocessing dan modeling.

Berikut adalah langkah-langkah utama yang dilakukan dalam tahap ini:
1. **Menampilkan Contoh Data Acak**  
   Digunakan untuk mendapatkan gambaran awal mengenai isi dan bentuk data dalam masing-masing DataFrame.

2. **Ukuran Dataset**  
   Menghitung jumlah baris dan kolom untuk mengetahui seberapa besar dataset yang tersedia.

3. **Struktur Data**  
   Menampilkan informasi tipe data, jumlah entri, dan memastikan tidak ada kolom dengan nilai kosong.

4. **Meninjau Nilai Unik**  
   Digunakan untuk mengetahui jumlah nilai yang berbeda pada setiap kolom dalam dataset. Langkah ini membantu mengidentifikasi fitur diskret, mendeteksi potensi duplikasi, serta memahami keragaman isi data seperti genres, title, dan skala rating.

5. **Statistik Deskriptif**  
   Memberikan ringkasan statistik untuk kolom numerik, seperti mean, standar deviasi, dan rentang nilai.

6. **Pemeriksaan Duplikasi**  
   Untuk memastikan tidak ada baris data yang terduplikasi, yang dapat memengaruhi hasil analisis.

7. **Pemeriksaan Nilai Kosong (*Null*)**  
   Memastikan tidak ada missing value pada kolom penting yang dapat menyebabkan error saat modeling.

8. **Visualisasi Distribusi Data**  
   Digunakan untuk melihat pola sebaran data pada fitur tertentu, seperti frekuensi genre film atau distribusi nilai rating. Visualisasi ini membantu memahami preferensi pengguna serta karakteristik konten, yang berguna dalam proses penyusunan model rekomendasi.

### EDA/Data Understanding Dataset `df_movies`

1. Menampilkan Contoh Data Acak
"""

df_movies.sample(5)

"""2. Ukuran Dataset"""

print("Jumlah total baris:", df_movies.shape[0])
print("Jumlah kolom:", df_movies.shape[1])
print("Jumlah film unik berdasarkan movieId:", df_movies["movieId"].nunique())

"""3. Struktur Data"""

print("Struktur DataFrame df_movies:")
df_movies.info()

"""4. Meninjau Nilai Unik"""

print("Jumlah nilai unik pada setiap kolom df_movies:")
print(df_movies.nunique())

# Tampilkan semua judul film yang sama (judul yang muncul lebih dari 1x)
df_movies['title'].value_counts().loc[lambda x: x > 1]

print("Genre yang tersedia:")
print(df_movies["genres"].unique())

"""5. Statistik Deskriptif"""

df_movies.describe()

"""6. Pemeriksaan Duplikasi"""

print("Jumlah data duplikat di df_movies:", df_movies.duplicated().sum())

"""Dari hasil pengecekan nilai unik, terdapat sedikit perbedaan jumlah antara `movieId` dan `title`. Hal ini disebabkan adanya film dengan judul yang sama tetapi memiliki `movieId` berbeda—biasanya karena perbedaan genre atau versi metadata.

Meskipun kolom `title` memiliki duplikat, hasil pemeriksaan `df_movies.duplicated()` menunjukkan bahwa tidak ada baris yang identik 100%, karena setiap `movieId` dan/atau `genres` berbeda.

Untuk kebutuhan modeling, `movieId` tetap digunakan sebagai identifier utama, sehingga perbedaan ini **tidak berdampak terhadap proses pemodelan**, baik pada pendekatan content-based maupun collaborative filtering. Oleh karena itu, duplikat pada kolom `title` dibiarkan dan tidak perlu dihapus.

7. Pemeriksaan Nilai Kosong (Null)
"""

print("Jumlah nilai null di setiap kolom:")
print(df_movies.isnull().sum())

"""8. Visualisasi Distribusi Data"""

# Memecah kolom genres lalu hitung frekuensi tiap genre
genre_series = df_movies['genres'].str.split('|').explode()
genre_counts = genre_series.value_counts().sort_values(ascending=False)

top_genres = genre_counts.head(10).reset_index()
top_genres.columns = ['genre', 'count']

# Visualisasi Top 10 Genre
plt.figure(figsize=(10,6))
sns.barplot(data=top_genres, x='count', y='genre', hue='genre', palette="viridis", dodge=False, legend=False)
plt.title("Top 10 Genre Film Terbanyak", fontsize=14)
plt.xlabel("Jumlah Film")
plt.ylabel("Genre")
plt.tight_layout()
plt.show()

"""### EDA/Data Understanding Dataset `df_ratings`

1. Menampilkan Contoh Data Acak
"""

df_ratings.sample(5)

"""2. Ukuran Dataset"""

print("Jumlah total baris:", df_ratings.shape[0])
print("Jumlah kolom:", df_ratings.shape[1])
print("Jumlah user unik:", df_ratings["userId"].nunique())
print("Jumlah film yang diberi rating:", df_ratings["movieId"].nunique())

"""3. Struktur Data"""

print("Struktur DataFrame df_ratings:")
df_ratings.info()

"""4. Meninjau Nilai Unik"""

print("Jumlah nilai unik pada setiap kolom df_ratings:")
print(df_ratings.nunique())

print("Skala rating yang digunakan:")
print(np.sort(df_ratings["rating"].unique()))

"""5. Statistik Deskriptif"""

df_ratings.describe()

"""6. Pemeriksaan Duplikasi"""

print("Jumlah data duplikat di df_ratings:", df_ratings.duplicated().sum())

"""7. Pemeriksaan Nilai Kosong (Null)"""

print("Jumlah nilai null di setiap kolom:")
print(df_ratings.isnull().sum())

"""8. Visualisasi Distribusi Data"""

# Menyiapkan bin untuk setiap interval rating
bins = np.arange(0.25, 5.75, 0.5)
counts, edges = np.histogram(df_ratings['rating'], bins=bins)

# Gradasi warna berdasarkan jumlah rating di setiap bin
norm_counts = counts / counts.max()
colors = plt.cm.Blues(norm_counts)

# Plot histogram
plt.figure(figsize=(8,5))
for i in range(len(counts)):
    plt.bar(
        x=(edges[i] + edges[i+1]) / 2,
        height=counts[i],
        width=0.45,
        color=colors[i],
        edgecolor='black'
    )

plt.title("Distribusi Skor Rating Film", fontsize=14)
plt.xlabel("Rating")
plt.ylabel("Jumlah")
plt.xticks(np.arange(0.5, 5.5 + 0.5, 0.5))
plt.tight_layout()
plt.show()

"""**Insight Data Understanding:**

Berdasarkan hasil eksplorasi data, dapat disimpulkan bahwa dataset sudah bersih tanpa nilai kosong maupun duplikasi. Genre film didominasi oleh kategori seperti Drama, Comedy, dan Action, yang menjadi indikasi kuat untuk digunakan dalam sistem rekomendasi berbasis konten. Sementara itu, mayoritas pengguna memberikan rating antara 3.0 hingga 4.0, yang menunjukkan preferensi umum terhadap film-film dengan kualitas sedang hingga tinggi. Temuan ini akan menjadi dasar penting dalam pemilihan fitur dan pendekatan model pada tahap berikutnya.

## **Data Preprocessing / Data Preparation & Modeling**

- Pembatasan Dataset untuk Efisiensi

Agar proses pelatihan lebih cepat dan ringan, digunakan subset dari dataset asli. Hanya 10.000 data film dan 5.000 data rating yang digunakan untuk Content-Based Filtering (CBF) dan Collaborative Filtering (CF).
"""

subset_movies = df_movies.iloc[:10000]
subset_ratings = df_ratings.iloc[:5000]

subset_movies.info()

subset_movies.head()

subset_ratings.info()

subset_ratings.head()

"""### **A. Content-Based Filtering (CBF)**

#### **A.1 Preprocessing untuk CBF**

Tahapan ini bertujuan menyiapkan data konten yang akan digunakan dalam sistem rekomendasi berbasis konten. Subset data disalin terlebih dahulu untuk menjaga keutuhan data asli dan membedakan penggunaannya dengan pendekatan lain seperti CF. Selanjutnya, kolom genre dipisahkan menjadi beberapa baris (*explode*) agar masing-masing genre dapat dianalisis secara individual oleh TF-IDF sebagai representasi teks. Langkah ini penting untuk memungkinkan perhitungan kemiripan antar film berdasarkan kontennya.
"""

# Salin data
df_movies_cb = subset_movies.copy()
df_ratings_cb = subset_ratings.copy()

# Memisahkan genre menjadi baris terpisah
df_movies_cb = df_movies_cb.assign(genres=df_movies_cb['genres'].str.split('|')).explode('genres')

"""#### **A.2 Model Development CBF**

Model dikembangkan dengan menerapkan TF-IDF Vectorizer pada kolom genre yang telah diproses, untuk mengubahnya menjadi representasi vektor numerik. Kemudian, *cosine similarity* dihitung antar film untuk mengukur tingkat kemiripan berdasarkan genre. Rekomendasi dihasilkan dengan mengambil film-film yang memiliki skor kemiripan tertinggi terhadap film yang dipilih pengguna.

- TF-IDF Vectorizer
"""

# Gunakan hasil explode langsung tanpa groupby
cbf_features = df_movies_cb.reset_index(drop=True)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer()
genre_matrix = vectorizer.fit_transform(cbf_features['genres'])

# Mapping array dari index ke fitur nama
genre_features = vectorizer.get_feature_names_out()
print("Jumlah fitur genre:", len(genre_features))
print("Daftar fitur genre:", genre_features)

# Hasil vektorisasi dalam bentuk matriks
genre_matrix.todense()

print("Bentuk matriks TF-IDF:", genre_matrix.shape)

# Preview isi matriks TF-IDF
tfidf_df = pd.DataFrame(
    genre_matrix.todense(),
    columns=vectorizer.get_feature_names_out(),
    index=cbf_features['title']
)
tfidf_df.sample(24, axis=1).sample(5, axis=0)

"""- Cosine Similarity"""

# Menghitung similarity antar baris
similarity_matrix = cosine_similarity(genre_matrix)

# Menggunakan index dan title sebagai identifier
similarity_df = pd.DataFrame(similarity_matrix, index=cbf_features['title'], columns=cbf_features['title'])

# Cosine Similarity Matrix Preview
print("Shape of similarity matrix:", similarity_df.shape)

# Menampilkan 10 baris × 5 kolom acak dari similarity antar judul
similarity_df.sample(10, axis=0).sample(5, axis=1)

"""- Recommendation Function"""

def cbf_recommend_movies(title, similarity_data=similarity_df, metadata=cbf_features[['title', 'genres']], k=10):
    if title not in similarity_data.columns:
        return f"Judul '{title}' tidak ditemukan dalam data."

    sim_scores = similarity_data[title]

    # Mencegah error jika bentuknya masih DataFrame
    if isinstance(sim_scores, pd.DataFrame):
        sim_scores = sim_scores.iloc[:, 0]

    sim_scores = sim_scores.drop(labels=[title], errors='ignore')
    sim_scores_sorted = sim_scores.sort_values(ascending=False)

    top_titles = sim_scores_sorted.head(k).index

    return pd.DataFrame(top_titles, columns=['title']) \
        .merge(metadata, on='title') \
        .drop_duplicates(subset='title') \
        .head(k)

"""#### **A.3 Top-N Recommendation CBF**

Pada tahap ini, sistem memberikan rekomendasi film berdasarkan kemiripan konten (*genre*) dengan film yang dipilih pengguna. Sistem mencari film-film lain yang memiliki skor *cosine similarity* tertinggi terhadap film tersebut, lalu menampilkan top-N rekomendasi. Pendekatan ini tidak bergantung pada data rating pengguna, sehingga cocok untuk *cold-start user*.
"""

title_of_movie = "Toy Story (1995)"

cbf_features[cbf_features['title'] == title_of_movie]

"""##### Top-5 Recommendation
Menampilkan 5 film yang paling mirip berdasarkan genre.
"""

print(f"Top-5 recommended movies similar to '{title_of_movie}':\n")
cbf_recommend_movies(title_of_movie, k=5)

"""##### Top-10 Recommendation
Menampilkan 10 film yang paling mirip berdasarkan genre.
"""

print(f"Top-10 recommended movies similar to '{title_of_movie}':\n")
cbf_recommend_movies(title_of_movie, k=10)

"""Dari hasil rekomendasi di atas, sistem mampu menyarankan film yang relevan berdasarkan judul yang dimasukkan, yakni "Toy Story (1995)". Film-film yang direkomendasikan memiliki kemiripan dalam hal genre, khususnya Adventure dan Action, yang menandakan bahwa sistem berhasil menemukan kesamaan konten antar film. Hal ini menunjukkan bahwa metode Content-Based Filtering bekerja secara efektif dalam mengenali karakteristik genre dari film yang disukai.

### **B. Collaborative Filtering (CF)**

#### **B.1 Preprocessing untuk CF**

Menyalin subset data dilakukan terlebih dahulu untuk menjaga keutuhan data asli dan membedakan penggunaan antar pendekatan (CBF dan CF).
Selanjutnya, dilakukan encoding numerik terhadap `userId` dan `movieId` untuk mempersiapkan data interaksi antara pengguna dan film. Data ini kemudian dibagi menjadi data pelatihan dan validasi. Berbeda dengan pendekatan CBF, tahap ini hanya menggunakan informasi rating sebagai dasar model, tanpa mempertimbangkan konten film seperti genre atau judul
"""

# Salin data
df_movies_cf = subset_movies.copy()
df_ratings_cf = subset_ratings.copy()

"""- Encode userId dan movieId

  Mengubah userId dan movieId ke dalam bentuk index numerik agar dapat diproses oleh model, karena algoritma machine learning tidak dapat langsung memproses data kategori dalam bentuk string atau ID asli.
"""

user_ids_cf = df_ratings_cf['userId'].unique().tolist()
movie_ids_cf = df_ratings_cf['movieId'].unique().tolist()

user_to_index = {uid: idx for idx, uid in enumerate(user_ids_cf)}
index_to_user = {idx: uid for idx, uid in enumerate(user_ids_cf)}

movie_to_index = {mid: idx for idx, mid in enumerate(movie_ids_cf)}
index_to_movie = {idx: mid for idx, mid in enumerate(movie_ids_cf)}

# Mapping ke DataFrame
df_ratings_cf['user'] = df_ratings_cf['userId'].map(user_to_index)
df_ratings_cf['movie'] = df_ratings_cf['movieId'].map(movie_to_index)

# Menampilkan hasil encoding
print("Daftar userId unik:", user_ids_cf[:10], "...")
print("Contoh mapping user → index:", list(user_to_index.items())[:5])
print("Contoh mapping index → user:", list(index_to_user.items())[:5])

print("Daftar movieId unik:", movie_ids_cf[:10], "...")
print("Contoh mapping movie → index:", list(movie_to_index.items())[:5])
print("Contoh mapping index → movie:", list(index_to_movie.items())[:5])

"""- Normalisasi rating

  Konversi tipe data dan pencarian nilai minimum–maksimum untuk proses normalisasi.
"""

# Konversi rating ke float dan cari min/max
df_ratings_cf['rating'] = df_ratings_cf['rating'].astype(np.float32)
min_rating = df_ratings_cf['rating'].min()
max_rating = df_ratings_cf['rating'].max()

# Ringkasan
print(len(user_to_index))
print(len(movie_to_index))
print("Jumlah user: {}, Jumlah film: {}, Nilai rating minimum: {}, Nilai rating maksimum: {}".format(
    len(user_to_index), len(movie_to_index), min_rating, max_rating
))

"""- Shuffle dan split data

  Mengacak data untuk menghilangkan bias urutan, kemudian mengekstrak fitur (user dan movie) serta label (rating) yang telah dinormalisasi. Setelah itu, data dibagi menjadi 80% data pelatihan dan 20% data validasi untuk melatih dan mengevaluasi model CF.
"""

# Mengacak data
df_ratings_cf = df_ratings_cf.sample(frac=1, random_state=42)

# Ekstraksi fitur dan normalisasi label
x_cf = df_ratings_cf[['user', 'movie']].values
y_cf = df_ratings_cf['rating'].apply(lambda r: (r - min_rating) / (max_rating - min_rating)).values

# Split 80% data train dan 20% data validasi
train_indices = int(0.8 * len(x_cf))
x_train_cf, x_val_cf, y_train_cf, y_val_cf = (
    x_cf[:train_indices],
    x_cf[train_indices:],
    y_cf[:train_indices],
    y_cf[train_indices:]
)

print(x_cf[:5])
print(y_cf[:5])

# Menyimpan jumlah entitas
num_users = len(user_ids_cf)
num_movies = len(movie_ids_cf)

# Ringkasan
print("Total keseluruhan data:", len(x_cf))
print("Jumlah data train:", len(x_train_cf))
print("Jumlah data validation:", len(x_val_cf))
print("Total user:", num_users)
print("Total movie:", num_movies)

"""#### **B.2 Model Development CF**

Model dibangun menggunakan pendekatan *embedding* untuk mewakili pengguna dan film dalam bentuk vektor laten. Model mempelajari pola interaksi untuk memprediksi skor rating yang mungkin diberikan pengguna terhadap film tertentu. Evaluasi dilakukan menggunakan metrik RMSE untuk mengukur seberapa akurat prediksi model terhadap data validasi.

-  Membangun Arsitektur Model: RecommenderNet
"""

class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_movies, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.user_embedding = layers.Embedding(
            input_dim=num_users,
            output_dim=embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(input_dim=num_users, output_dim=1)

        self.movie_embedding = layers.Embedding(
            input_dim=num_movies,
            output_dim=embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.movie_bias = layers.Embedding(input_dim=num_movies, output_dim=1)
        self.dropout = layers.Dropout(0.3)

    def call(self, inputs):
        user_vec = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        movie_vec = self.movie_embedding(inputs[:, 1])
        movie_bias = self.movie_bias(inputs[:, 1])

        dot_user_movie = tf.tensordot(user_vec, movie_vec, 2)
        x = dot_user_movie + user_bias + movie_bias
        return tf.nn.sigmoid(x)

"""- Kompilasi dan Training Model"""

model_cf = RecommenderNet(num_users, num_movies, embedding_size=32)

model_cf.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# EarlyStopping
earlystop = tf.keras.callbacks.EarlyStopping(
    monitor='val_root_mean_squared_error', patience=10, restore_best_weights=True
)

# Pelatihan model
history_cf = model_cf.fit(
    x_train_cf, y_train_cf,
    epochs=100,
    validation_data=(x_val_cf, y_val_cf),
    batch_size=8,
    callbacks=[earlystop]
)

"""- Visualisasi Hasil Pelatihan"""

# RMSE Plot
plt.plot(history_cf.history['root_mean_squared_error'])
plt.plot(history_cf.history['val_root_mean_squared_error'])
plt.title('Model Evaluation (RMSE)')
plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper right')
plt.grid(True)
plt.show()

# Loss Plot
plt.plot(history_cf.history['loss'])
plt.plot(history_cf.history['val_loss'])
plt.title('Model Evaluation (Loss)')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper right')
plt.grid(True)
plt.show()

"""#### **B.3 Top-N Recommendation CF**

Tahapan ini menampilkan hasil rekomendasi dari model *collaborative filtering *yang telah dilatih. Dalam proses ini, satu pengguna dipilih secara acak, lalu sistem akan memprediksi skor ketertarikan pengguna tersebut terhadap film-film yang belum ditonton. Model kemudian memilih top-N film dengan skor prediksi tertinggi. Pendekatan ini menghasilkan rekomendasi yang dipersonalisasi berdasarkan pola rating dari pengguna lain yang memiliki preferensi serupa.

- Menyiapkan Data Pengguna & Film Kandidat Rekomendasi
"""

# Dataset untuk testing sistem rekomendasi
movies_data = df_movies_cf
user_ratings = df_ratings_cf

# Memilih satu user secara acak
random_user = user_ratings.user.sample(1).iloc[0]

# Film yang sudah diberi rating oleh user tersebut
rated_movies = user_ratings[user_ratings.user == random_user]

# Film yang belum ditonton (belum dirating)
candidate_movies = movies_data[~movies_data['movieId'].isin(rated_movies.movie.values)]['movieId']
candidate_movies = list(
    set(candidate_movies).intersection(set(movie_to_index.keys()))
)

# Encoding untuk user dan daftar film kandidat
encoded_candidates = [[movie_to_index.get(mid)] for mid in candidate_movies]
encoded_user = user_to_index.get(random_user)

# Array input (user_id, movie_id) untuk prediksi
prediction_input = np.hstack(
    ([[encoded_user]] * len(encoded_candidates), encoded_candidates)
).astype(np.int32)

"""- Prediksi Rating & Pilih Top 10 Film"""

# Prediksi rating oleh model CF
predicted_scores = model_cf.predict(prediction_input).flatten()

# Top-10 film dengan skor prediksi tertinggi
top_movie_indices = predicted_scores.argsort()[-10:][::-1]

# Konversi kembali ke movie ID asli
top_movie_ids = [
    index_to_movie.get(encoded_candidates[i][0]) for i in top_movie_indices
]

"""- Menampilkan Rekomendasi & Riwayat User"""

print(f"Top-N Recomendation for user: {random_user}")
print("=" * 50)

top_rated = (
    rated_movies.sort_values(by="rating", ascending=False)
    .head(5)
    .movieId.values
)

if len(top_rated) == 0:
    print("This user hasn't rated any movies yet.")
else:
    print(f"Top {len(top_rated)} favorite movie pick(s) from the user:")
    print("-" * 50)
    top_rated_titles = movies_data[movies_data.movieId.isin(top_rated)]
    for row in top_rated_titles.itertuples():
        print(f"{row.title} : {row.genres}")

print("-" * 50)
print("Top 10 Movie Recommendation:")
print("-" * 50)

recommendations = movies_data[movies_data.movieId.isin(top_movie_ids)]
for row in recommendations.itertuples():
    print(f"{row.title} : {row.genres}")

"""**Insight hasil Top-N Recommendation untuk user 23:**

- Preferensi pengguna tampak dominan pada genre **Action**, **Drama**, dan **Crime**, dengan kombinasi elemen **Thriller**, **Fantasy**, dan **Sci-Fi**, seperti yang terlihat dari film *Heat*, *The Green Mile*, dan *Laputa: Castle in the Sky*.

- Rekomendasi yang diberikan cukup relevan dan konsisten dengan preferensi tersebut, antara lain:

  - *The Terminator*, *The Great Escape*, dan *Boot, Das* menawarkan tema aksi dan perang yang sejalan dengan film favorit pengguna.

  - *Chinatown* dan *M* menggambarkan crime dan thriller klasik, memperluas cakupan pada film-film kultus dengan tone serupa.

  - *Duck Soup* dan *The Quiet Man* menambahkan nuansa komedi klasik dan drama romantis, memberikan opsi eksplorasi di luar genre utama pengguna namun masih dalam batas relevansi.

## **Evaluasi Model**

### **A. Content-Based Filtering (CBF)**

- Fungsi Evaluasi Akurasi CBF (Precision@K)
"""

def cbf_precision_score(title, k=10):
    if title not in cbf_features['title'].values:
        return f"Judul '{title}' tidak ditemukan dalam metadata."

    # Ambil genre unik dari title yang diminta
    input_genres = cbf_features[cbf_features['title'] == title]['genres'].unique().tolist()
    if not input_genres:
        return "Tidak ada genre untuk film ini."

    # Ambil rekomendasi
    recommended = cbf_recommend_movies(title, k=k)
    if isinstance(recommended, str):
        return recommended

    # Hitung berapa baris rekomendasi yang punya genre sama dengan genre input
    relevant_count = sum(1 for genre in recommended['genres'] if genre in input_genres)
    precision = relevant_count / k

    return precision, relevant_count

"""- Evaluasi Akurasi"""

cbf_precision_score("Toy Story (1995)", k=5)

cbf_precision_score("Toy Story (1995)", k=10)

"""- Menampilkan Hasil Evaluasi"""

precision, count = cbf_precision_score("Toy Story (1995)", k=5)
print(f"Precision@5 untuk 'Toy Story (1995)': {precision:.2f} ({count} relevan dari 5)")

precision_10, count_10 = cbf_precision_score("Toy Story (1995)", k=10)
print(f"Precision@10 untuk 'Toy Story (1995)': {precision_10:.2f} ({count_10} relevan dari 10)")

"""Tabel ringkasan evaluasi CBF:

| Metric         | K=5 | K=10 |
|----------------|-----|------|
| Precision@K    | 0.80| 0.70 |
| Relevant Items | 4/5 | 7/10 |

Tabel di atas menunjukkan hasil evaluasi CBF untuk film Toy Story (1995):

- Precision@5 = 0.80 → 4 dari 5 rekomendasi sesuai genre.
- Precision@10 = 0.70 → 7 dari 10 rekomendasi relevan.


Hasil ini menunjukkan bahwa model cukup akurat, terutama untuk rekomendasi jumlah kecil.

### **B. Collaborative Filtering (CF)**

- Evaluasi Kuantitatif (RMSE)
"""

final_val_rmse = history_cf.history['val_root_mean_squared_error'][-1]
final_train_rmse = history_cf.history['root_mean_squared_error'][-1]
final_val_loss = history_cf.history['val_loss'][-1]

print(f"Validation RMSE akhir: {final_val_rmse:.4f}")
print(f"Training RMSE akhir: {final_train_rmse:.4f}")
print(f"Validation Loss akhir: {final_val_loss:.4f}")

"""- Ringkasan evaluasi model CF

| Metrik             | Nilai   | Keterangan                 |
|--------------------|---------|----------------------------|
| Validation RMSE    | 0.2323 | Sudah rendah dan stabil    |
| Training RMSE      | 0.1516  | Model terlatih dengan baik |
| Validation Loss    | 0.6438  | Tidak overfitting          |
| Epoch Berakhir     | 31/100  | Berhenti oleh EarlyStopping |


Model CF menunjukkan performa yang baik dengan RMSE validasi yang rendah dan stabil. Perbedaan RMSE antara data training dan validasi cukup wajar, menandakan generalisasi yang bagus. EarlyStopping aktif dan menghentikan training di epoch ke-31 karena tidak ada peningkatan signifikan, yang menunjukkan model sudah mencapai titik optimal. Penggunaan embedding 32 dan regularisasi terbukti efektif.

## **Kesimpulan**

Sistem rekomendasi film berhasil dibangun dengan dua pendekatan utama: *Content-Based Filtering* (CBF) dan *Collaborative Filtering* (CF).

- Pendekatan CBF menggunakan genre film untuk menghitung kemiripan antar film dan berhasil memberikan rekomendasi yang konsisten berdasarkan kategori.

- Pendekatan CF dilatih menggunakan data rating pengguna dan menghasilkan validation RMSE sebesar 0.2324, menunjukkan performa yang baik dan stabil.

Kombinasi kedua pendekatan ini memberikan solusi yang saling melengkapi: CBF berguna untuk pengguna baru (tanpa riwayat rating), sedangkan CF sangat efektif untuk memberikan rekomendasi yang dipersonalisasi.

Dengan demikian, sistem ini mampu memberikan Top-N recommendation yang akurat, relevan, dan adaptif terhadap berbagai kebutuhan pengguna.

## **Referensi**

[1] S. Algor and S. Srivastava, “Hybrid Movie Recommendation System using Content-Based and Collaborative Filtering,” in *Proc. 2020 Int. Conf. Electronics and Sustainable Communication Systems (ICESC)*, 2020, pp. 102–106. doi: [10.1109/ICESC48915.2020.9155879](https://doi.org/10.1109/ICESC48915.2020.9155879)

[2] A. R. Rukmi, F. A. Permana, and D. E. Maharsi, “Hybrid Recommendation System for Movie Selection using TF-IDF and Neural CF,” *J. Appl. Data Sci.*, vol. 4, no. 3, pp. 211–221, 2022. doi: [10.47738/jads.v4i3.115](https://doi.org/10.47738/jads.v4i3.115)

[3] I. Nurhaida and M. Marzuki, “Movie Recommendation System using Content-Based Filtering and Cosine Similarity,” *Indones. J. Inf. Commun. Technol.*, vol. 9, no. 2, pp. 101–110, 2021. doi: [10.21108/ijoict.v9i2.747](https://doi.org/10.21108/ijoict.v9i2.747)

[4] K. Nand and R. Tripathi, “Movie Recommendation System Based on Hybrid Filtering using K-Means and TF-IDF,” *J. Adv. Inf. Technol.*, vol. 12, no. 3, pp. 189–196, 2021. doi: [10.12720/jait.12.3.189-196](https://doi.org/10.12720/jait.12.3.189-196)
"""